{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "adc7561f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model and tokenizer loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "# Cell 1 — Import libraries & load model/tokenizer\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "from keras.models import load_model\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import pickle\n",
    "\n",
    "# FIXED → Correct path to src folder\n",
    "sys.path.append(os.path.abspath(\"../src\"))\n",
    "\n",
    "# Import Member A's function\n",
    "from data_preparation import prepare_data\n",
    "\n",
    "MODEL_PATH = \"../saved_model/sentiment_model.h5\"\n",
    "TOKENIZER_PATH = \"../saved_model/tokenizer.pkl\"\n",
    "MAX_LEN = 120\n",
    "\n",
    "model = load_model(MODEL_PATH)\n",
    "\n",
    "with open(TOKENIZER_PATH, \"rb\") as f:\n",
    "    tokenizer = pickle.load(f)\n",
    "\n",
    "print(\"Model and tokenizer loaded successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "44c2f4c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: I really love this product so much\n",
      " → Prediction: Positive (0.7037)\n",
      "------------------------------------------------------------\n",
      "Input: This is the worst thing I have ever bought\n",
      " → Prediction: Negative (0.0357)\n",
      "------------------------------------------------------------\n",
      "Input: The quality is okay, not great but not terrible\n",
      " → Prediction: Negative (0.0613)\n",
      "------------------------------------------------------------\n",
      "Input: I am very disappointed with this chair\n",
      " → Prediction: Negative (0.0913)\n",
      "------------------------------------------------------------\n",
      "Input: Amazing value for money, highly recommended!\n",
      " → Prediction: Positive (0.7693)\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#clean and predict \n",
    "def clean_text(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Normalise input: lowercase, remove non-alphanumeric chars,\n",
    "    collapse multiple spaces. MUST match training + Flask.\n",
    "    \"\"\"\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"[^a-z0-9\\s]\", \" \", text)\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "    return text\n",
    "\n",
    "\n",
    "def predict_sentiment(text: str):\n",
    "    \"\"\"\n",
    "    Predict sentiment for a single input sentence.\n",
    "    Returns (label, probability).\n",
    "    \"\"\"\n",
    "    cleaned = clean_text(text)\n",
    "    seq = tokenizer.texts_to_sequences([cleaned])\n",
    "    seq = pad_sequences(\n",
    "        seq,\n",
    "        maxlen=MAX_LEN,\n",
    "        padding=\"post\",\n",
    "        truncating=\"post\"\n",
    "    )\n",
    "    prob = float(model.predict(seq, verbose=0)[0][0])\n",
    "    label = \"Positive\" if prob >= 0.5 else \"Negative\"\n",
    "    return label, prob\n",
    "\n",
    "test_sentences = [\n",
    "    \"I really love this product so much\",\n",
    "    \"This is the worst thing I have ever bought\",\n",
    "    \"The quality is okay, not great but not terrible\",\n",
    "    \"I am very disappointed with this chair\",\n",
    "    \"Amazing value for money, highly recommended!\"\n",
    "]\n",
    "\n",
    "for s in test_sentences:\n",
    "    label, prob = predict_sentiment(s)\n",
    "    print(f\"Input: {s}\")\n",
    "    print(f\" → Prediction: {label} ({prob:.4f})\")\n",
    "    print(\"-\" * 60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7d29fda8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current notebook path: c:\\Users\\legia\\GitHub\\NLP-Project\\NLP-Sentiment-Analysis-Group\\evaluation\n",
      "Switching directory to: c:\\Users\\legia\\GitHub\\NLP-Project\\NLP-Sentiment-Analysis-Group\n",
      "Loading dataset...\n",
      "Total reviews after filtering: 7999\n",
      "Shapes:\n",
      "  X_train: (5599, 120) y_train: 5599\n",
      "  X_val:   (1200, 120) y_val: 1200\n",
      "  X_test:  (1200, 120) y_test: 1200\n",
      "Returned to evaluation directory: c:\\Users\\legia\\GitHub\\NLP-Project\\NLP-Sentiment-Analysis-Group\\evaluation\n",
      "Dataset loaded:\n",
      "  X_train: (5599, 120) | y_train: (5599,)\n",
      "  X_val:   (1200, 120) | y_val:   (1200,)\n",
      "  X_test:  (1200, 120) | y_test: (1200,)\n"
     ]
    }
   ],
   "source": [
    "# Cell 4 – Load dataset splits using your prepare_data()\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "from data_preparation import prepare_data\n",
    "\n",
    "print(\"Current notebook path:\", os.getcwd())\n",
    "\n",
    "# Move to project root so 'data' folder exists\n",
    "project_root = os.path.abspath(\"..\")\n",
    "print(\"Switching directory to:\", project_root)\n",
    "os.chdir(project_root)\n",
    "\n",
    "# Call prepare_data() exactly as defined (no arguments)\n",
    "result = prepare_data()\n",
    "\n",
    "# Switch back to evaluation folder\n",
    "eval_dir = os.path.abspath(\"./evaluation\")\n",
    "os.chdir(eval_dir)\n",
    "print(\"Returned to evaluation directory:\", os.getcwd())\n",
    "\n",
    "# Unpack returned lists\n",
    "X_train, X_val, X_test, y_train, y_val, y_test = result\n",
    "\n",
    "# FIX: Convert lists to numpy arrays\n",
    "X_train = np.array(X_train)\n",
    "X_val   = np.array(X_val)\n",
    "X_test  = np.array(X_test)\n",
    "\n",
    "y_train = np.array(y_train)\n",
    "y_val   = np.array(y_val)\n",
    "y_test  = np.array(y_test)\n",
    "\n",
    "print(\"Dataset loaded:\")\n",
    "print(\"  X_train:\", X_train.shape, \"| y_train:\", y_train.shape)\n",
    "print(\"  X_val:  \", X_val.shape,   \"| y_val:  \", y_val.shape)\n",
    "print(\"  X_test: \", X_test.shape,  \"| y_test:\", y_test.shape)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
